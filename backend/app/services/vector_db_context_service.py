from app.rag.rag import build_vector_db_retriever
from app.rag.vector_db import format_docs_with_metadata
from app.schemas.scenario_preparation import ConversationScenarioBase
from app.services.voice_analysis_service import analyze_voice_gemini_from_file


def build_query_prep_feedback(
    session_context: ConversationScenarioBase,
    user_audio_analysis: str | None = None,
    user_transcript: str | None = None,
) -> str:
    """
    Constructs a detailed query string based on the conversation scenario
    for preparation and feedback

    Args:
        session_context (ConversationScenarioBase): The scenario for the current session,
            including category, persona, and situational background facts
        user_audio_analysis (str, optional): Description of the tone, emotion, or delivery
            of the user
        user_transcript (str, optional): Transcript of what the user said

    Returns:
        str: A concatenated query string incorporating all available context
    """
    parts = []

    if session_context.category:
        parts.append(f'This is a/an {session_context.category}.')

    if session_context.persona:
        parts.append(f'The HR employee is speaking to {session_context.persona}.')

    if session_context.situational_facts:
        parts.append(f'The context is: {session_context.situational_facts}')

    if user_transcript:
        parts.append(f'The HR employee said: {user_transcript}.')

    if user_audio_analysis:
        parts.append(f'It was spoken in the manner: {user_audio_analysis}.')

    return ' '.join(parts)


def build_query_general(
    other_context: list[str] | None = None,
    user_audio_analysis: str | None = None,
    user_transcript: str | None = None,
) -> str:
    """
    Builds a query string for general purposes, i.e. usually OTHER than preparation and feedback

    Args:
        other_context (list of str, optional): A list of strings describing general
            context. Not tied to a certain schema
        user_audio_analysis (str, optional):Description of the tone, emotion, or delivery
            of the user
        user_transcript (str, optional): Transcript of what the user said

    Returns:
        str: A concatenated query string incorporating all available context
    """
    parts = []
    if other_context and len(other_context) > 0:
        parts = parts + ['The general context is: '] + other_context

    if user_transcript:
        parts.append(f'The HR employee said: {user_transcript}.')

    if user_audio_analysis:
        parts.append(f'It was spoken in the manner: {user_audio_analysis}.')

    return ' '.join(parts)


def query_vector_db(
    session_context: ConversationScenarioBase | list[str] | None = None,
    user_audio_path: str | None = None,
    user_transcript: str | None = None,
) -> tuple[str, list[dict]]:
    """
    Retrieves relevant documents from the vector database based on the session context,
    user audio and text

    Args:
        session_context (ConversationScenarioBase or list of str, optional):
            Either a structured conversation scenario object or a list of context strings
        user_audio_path (str, optional): File path to the user's audio recording for analysis
        user_transcript (str, optional): Transcript of what the user said

    Returns:
        tuple[str, list[dict]]: A tuple of:
    1) A single string containing the concatenated contents of all documents, relevant
    to the query
    2) The documents' metadata in an array of dicts
    """
    try:
        voice_analysis = None
        if user_audio_path:
            voice_analysis = analyze_voice_gemini_from_file(user_audio_path)

        if all(x is None for x in [session_context, user_audio_path, user_transcript]):
            return '', []

        if isinstance(session_context, ConversationScenarioBase):
            query = build_query_prep_feedback(session_context, voice_analysis, user_transcript)
        else:
            query = build_query_general(session_context, voice_analysis, user_transcript)
        retriever = build_vector_db_retriever()
        if retriever:
            return format_docs_with_metadata(retriever.invoke(query))
        else:
            return '', []
    except Exception as e:
        print(f'Failed to query vector db: {e}')
        return '', []


def query_vector_db_and_prompt(
    generated_object: str,
    session_context: ConversationScenarioBase | list[str] | None = None,
    user_audio_path: str | None = None,
    user_transcript: str | None = None,
) -> str:
    """
    Creates a prompt extension for an object that's generated by an LLM, e.g. general output,
    objectives etc. It includes relevant documents from the vector database
    based on the session context, user audio and text, which are fetched in the background.

    Args:
        generated_object (str): The object, whose prompt we're extending (is being generated)
        session_context (ConversationScenarioBase or list of str, optional):
            Either a structured conversation scenario object or a list of context strings
        user_audio_path (str, optional): File path to the user's audio recording for analysis
        user_transcript (str, optional): Transcript of what the user said

    Returns:
        str: A prompt extension incorporating all documents, relevant to the query
    """
    vector_db_docs, metadata = query_vector_db(
        session_context=session_context,
        user_audio_path=user_audio_path,
        user_transcript=user_transcript,
    )
    if vector_db_docs and len(vector_db_docs) > 0:
        hr_docs_context = (
            f'\nThe {generated_object} you generate should comply with '
            f'the following HR Guideline excerpts:\n'
            f'{vector_db_docs}\n'
        )
    else:
        hr_docs_context = ''

    return hr_docs_context
